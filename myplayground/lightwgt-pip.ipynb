{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f01fc2d-41c9-4e19-8b49-528bb211e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_FLAG = \"--user\"\n",
    "!pip3 install --user google-cloud-aiplatform==1.18.1\n",
    "#!pip3 install  --upgrade google-cloud-aiplatform \n",
    "#!pip3 install -U google-cloud-storage  \n",
    "!pip3 install --user google-cloud-pipeline-components\n",
    "! pip3 install --user -U google-cloud-storage \n",
    "!pip3 install --user  kfp==1.8.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6e8e1a-6dde-4f28-935c-e3228fa4b0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee14417-a515-437c-abd0-e9f02bee58eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "! python3 -c \"import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5e75b5-c9d7-4467-93d3-a1165dff35e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "PROJECT_ID = shell_output[0]\n",
    "print(\"Project ID:\", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069e5ecb-88f7-4182-ace0-c968360a781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud config set project $PROJECT_ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69872351-5698-427f-ae81-52c01de9b733",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df93c5d-fd1d-4419-9472-64da90c2d991",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"gs://{}-bucket-ai-pip\".format(PROJECT_ID)\n",
    "!gsutil mb -l us-central1 $BUCKET_NAME # You only need to run this once\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}/lightwght-pip-root/\"\n",
    "PIPELINE_ROOT = f\"{BUCKET_NAME}/lightwght-pip-root/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37212936-dc93-4de9-937b-dffac5b0e619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# We'll use this beta library for metadata querying\n",
    "from google.cloud import aiplatform as aip, aiplatform_v1beta1 as aipbeta\n",
    "from google.cloud.aiplatform import pipeline_jobs \n",
    "from kfp.v2 import compiler, dsl\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input,InputPath, Metrics, Model, Output,\n",
    "                        OutputPath, component)\n",
    "from google.oauth2 import service_account as sa\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c68327-0aa7-4c60-9b32-1f5827fd13ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = get_ipython().run_line_magic(\"env\", \"PATH\")\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin\n",
    "shell_output = !gcloud auth list 2>/dev/null\n",
    "SERVICE_ACCOUNT = shell_output[2].replace(\"*\", \"\").strip()\n",
    "print(\"Service Account:\", SERVICE_ACCOUNT)\n",
    "shell_output = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "PROJECT_ID = shell_output[0]\n",
    "print(\"Project ID: \", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782d24f5-2e03-483b-ae8d-793ac9c8d582",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_ENDPOINT = \"{}-aiplatform.googleapis.com\".format(REGION)\n",
    "!export GOOGLE_APPLICATION_CREDENTIALS=\"/home/jupyter/src/myplayground/raniamoh-playground-ai.json\"\n",
    "!gcloud auth activate-service-account ai-piplinesa@raniamoh-playground.iam.gserviceaccount.com --key-file=\"/home/jupyter/src/myplayground/raniamoh-playground-ai.json\"\n",
    "!gcloud iam service-accounts add-iam-policy-binding 189908348872-compute@developer.gserviceaccount.com  --member=serviceAccount:ai-piplinesa@raniamoh-playground.iam.gserviceaccount.com  --role=roles/iam.serviceAccountUser --project=raniamoh-playground\n",
    "!gcloud iam service-accounts add-iam-policy-binding ai-piplinesa@raniamoh-playground.iam.gserviceaccount.com  --member=serviceAccount:ai-piplinesa@raniamoh-playground.iam.gserviceaccount.com  --role=roles/iam.serviceAccountUser --project=raniamoh-playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647534cb-2de6-49be-9e4d-55241c0149bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "aip.init(project=PROJECT_ID, location=REGION,  staging_bucket=BUCKET_URI, credentials=sa.Credentials.from_service_account_file(\n",
    "    '/home/jupyter/src/myplayground/raniamoh-playground-ai.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bf7797-d708-48fb-a314-c21cb797e2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component\n",
    "def preprocess(\n",
    "    # An input parameter of type string.\n",
    "    message: str,\n",
    "    # Use Output to get a metadata-rich handle to the output artifact\n",
    "    # of type `Dataset`.\n",
    "    output_dataset_one: Output[Dataset],\n",
    "    # A locally accessible filepath for another output artifact of type\n",
    "    # `Dataset`.\n",
    "    output_dataset_two_path: OutputPath(\"Dataset\"),\n",
    "    # A locally accessible filepath for an output parameter of type string.\n",
    "    output_parameter_path: OutputPath(str),\n",
    "):\n",
    "    \"\"\"'Mock' preprocessing step.\n",
    "    Writes out the passed in message to the output \"Dataset\"s and the output message.\n",
    "    \"\"\"\n",
    "    output_dataset_one.metadata[\"hello\"] = \"there\"\n",
    "    # Use OutputArtifact.path to access a local file path for writing.\n",
    "    # One can also use OutputArtifact.uri to access the actual URI file path.\n",
    "    with open(output_dataset_one.path, \"w\") as f:\n",
    "        f.write(message)\n",
    "\n",
    "    # OutputPath is used to just pass the local file path of the output artifact\n",
    "    # to the function.\n",
    "    with open(output_dataset_two_path, \"w\") as f:\n",
    "        f.write(message)\n",
    "\n",
    "    with open(output_parameter_path, \"w\") as f:\n",
    "        f.write(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfa4c19-ffa1-4594-82e3-f8a590d22624",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.9\",  # Use a different base image.\n",
    ")\n",
    "def train(\n",
    "    # An input parameter of type string.\n",
    "    message: str,\n",
    "    # Use InputPath to get a locally accessible path for the input artifact\n",
    "    # of type `Dataset`.\n",
    "    dataset_one_path: InputPath(\"Dataset\"),\n",
    "    # Use InputArtifact to get a metadata-rich handle to the input artifact\n",
    "    # of type `Dataset`.\n",
    "    dataset_two: Input[Dataset],\n",
    "    # Output artifact of type Model.\n",
    "    imported_dataset: Input[Dataset],\n",
    "    model: Output[Model],\n",
    "    # An input parameter of type int with a default value.\n",
    "    num_steps: int = 3,\n",
    "    # Use NamedTuple to return either artifacts or parameters.\n",
    "    # When returning artifacts like this, return the contents of\n",
    "    # the artifact. The assumption here is that this return value\n",
    "    # fits in memory.\n",
    ") -> NamedTuple(\n",
    "    \"Outputs\",\n",
    "    [\n",
    "        (\"output_message\", str),  # Return parameter.\n",
    "        (\"generic_artifact\", Artifact),  # Return generic Artifact.\n",
    "    ],\n",
    "):\n",
    "    \"\"\"'Mock' Training step.\n",
    "    Combines the contents of dataset_one and dataset_two into the\n",
    "    output Model.\n",
    "    Constructs a new output_message consisting of message repeated num_steps times.\n",
    "    \"\"\"\n",
    "\n",
    "    # Directly access the passed in GCS URI as a local file (uses GCSFuse).\n",
    "    with open(dataset_one_path, \"r\") as input_file:\n",
    "        dataset_one_contents = input_file.read()\n",
    "\n",
    "    # dataset_two is an Artifact handle. Use dataset_two.path to get a\n",
    "    # local file path (uses GCSFuse).\n",
    "    # Alternately, use dataset_two.uri to access the GCS URI directly.\n",
    "    with open(dataset_two.path, \"r\") as input_file:\n",
    "        dataset_two_contents = input_file.read()\n",
    "\n",
    "    with open(model.path, \"w\") as f:\n",
    "        f.write(\"My Model\")\n",
    "\n",
    "    with open(imported_dataset.path, \"r\") as f:\n",
    "        data = f.read()\n",
    "    print(\"Imported Dataset:\", data)\n",
    "\n",
    "    # Use model.get() to get a Model artifact, which has a .metadata dictionary\n",
    "    # to store arbitrary metadata for the output artifact. This metadata will be\n",
    "    # recorded in Managed Metadata and can be queried later. It will also show up\n",
    "    # in the UI.\n",
    "    model.metadata[\"accuracy\"] = 0.9\n",
    "    model.metadata[\"framework\"] = \"Tensorflow\"\n",
    "    model.metadata[\"time_to_train_in_seconds\"] = 257\n",
    "\n",
    "    artifact_contents = \"{}\\n{}\".format(dataset_one_contents, dataset_two_contents)\n",
    "    output_message = \" \".join([message for _ in range(num_steps)])\n",
    "    return (output_message, artifact_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4069347e-4bd1-48b4-9b41-c16b60310fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component\n",
    "def read_artifact_input(\n",
    "    generic: Input[Artifact],\n",
    "):\n",
    "    with open(generic.path, \"r\") as input_file:\n",
    "        generic_contents = input_file.read()\n",
    "        print(f\"generic contents: {generic_contents}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5abaed6-e753-448c-a750-4b8b7b72bc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    # Default pipeline root. You can override it when submitting the pipeline.\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    # A name for the pipeline. Use to determine the pipeline Context.\n",
    "    name=\"metadata-pipeline-v2\",\n",
    ")\n",
    "def pipeline(message: str):\n",
    "    importer = dsl.importer(\n",
    "        artifact_uri=\"gs://ml-pipeline-playground/shakespeare1.txt\",\n",
    "        artifact_class=Dataset,\n",
    "        reimport=False,\n",
    "    )\n",
    "    preprocess_task = preprocess(message=message)\n",
    "    train_task = train(\n",
    "        dataset_one_path=preprocess_task.outputs[\"output_dataset_one\"],\n",
    "        dataset_two=preprocess_task.outputs[\"output_dataset_two_path\"],\n",
    "        imported_dataset=importer.output,\n",
    "        message=preprocess_task.outputs[\"output_parameter_path\"],\n",
    "        num_steps=5,\n",
    "    )\n",
    "    read_task = read_artifact_input(  # noqa: F841\n",
    "        train_task.outputs[\"generic_artifact\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6995fd-5916-451d-ba32-20f1bbd39f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline, package_path=\"lightweight_pipeline.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb8d784-3bb0-4747-9b5d-7486a7219b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "DISPLAY_NAME = \"shakespeare_\" + TIMESTAMP\n",
    "\n",
    "job = aip.PipelineJob(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    template_path=\"lightweight_pipeline.json\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    parameter_values={\"message\": \"Hello, World\"},\n",
    ")\n",
    "\n",
    "job.run()\n",
    "\n",
    "#! rm lightweight_pipeline.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a415f2-1056-48cb-a818-246fa9ebc9a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-10.m98",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-10:m98"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
